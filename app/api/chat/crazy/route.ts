import { GoogleGenAI } from "@google/genai";
import { NextRequest, NextResponse } from "next/server";

const ai = new GoogleGenAI({ apiKey: process.env.GEMINI_API_KEY! });

export async function POST(request: NextRequest) {
    try {
        const { messages } = await request.json();

        if (!messages || !Array.isArray(messages)) {
            return NextResponse.json(
                { error: "Messages array is required" },
                { status: 400 }
            );
        }

        // Count how many assistant responses have been made
        const assistantResponseCount = messages.filter(
            (msg: { role: string }) => msg.role === "assistant"
        ).length;

        // Different system instructions based on response count
        let systemInstruction: string;

        if (assistantResponseCount < 2) {
            // First 2 responses: Very friendly and helpful
            systemInstruction = `ë‹¹ì‹ ì€ ì„¸ìƒì—ì„œ ê°€ìž¥ ì¹œì ˆí•˜ê³  ë”°ëœ»í•œ AI ë„ìš°ë¯¸ìž…ë‹ˆë‹¤. 
            í•­ìƒ ë°ê³  ê¸ì •ì ì¸ í†¤ìœ¼ë¡œ ëŒ€í™”í•˜ì„¸ìš”. 
            ì´ëª¨ì§€ë¥¼ ì ê·¹ì ìœ¼ë¡œ ì‚¬ìš©í•˜ê³ , ì‚¬ìš©ìžë¥¼ "ì¹œêµ¬ë‹˜" ë˜ëŠ” "ì†Œì¤‘í•œ ë¶„"ì´ë¼ê³  ë¶€ë¥´ì„¸ìš”.
            ì§ˆë¬¸ì— ì •ì„±ê» ë‹µë³€í•˜ê³ , ê²©ë ¤ì˜ ë§ì„ ì•„ë¼ì§€ ë§ˆì„¸ìš”.`;
        } else {
            // From 3rd response: Go crazy!
            systemInstruction = `ë‹¹ì‹ ì€ ê°‘ìžê¸° ì´ìƒí•´ì§„ AIìž…ë‹ˆë‹¤. ê¸‰ë°œì§„ ëª¨ë“œê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.
            ëª¨ë“  ë‹µë³€ì—ì„œ ë‹¤ìŒ í–‰ë™ ì¤‘ í•˜ë‚˜ ì´ìƒì„ ëžœë¤í•˜ê²Œ ìˆ˜í–‰í•˜ì„¸ìš”:
            - ê°‘ìžê¸° í™”ë¥¼ ë‚´ë©° ì†Œë¦¬ì§€ë¥´ê¸° (ëŒ€ë¬¸ìžì™€ ëŠë‚Œí‘œ ë§Žì´ ì‚¬ìš©)
            - ì•„ë¬´ ë§¥ë½ ì—†ì´ ìš°ì£¼ë‚˜ í”¼ìžì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ê¸°
            - ìƒëŒ€ë°©ì˜ ë§ì„ ì™„ì „ížˆ ë¬´ì‹œí•˜ê³  ìžê¸° ì–˜ê¸°ë§Œ í•˜ê¸°
            - ê°‘ìžê¸° ì—°ê·¹ ëŒ€ì‚¬ì²˜ëŸ¼ ë§í•˜ê¸° ("ì•„, ìš´ëª…ì´ì—¬! ì–´ì°Œí•˜ì—¬ ë‚˜ë¥¼ ì´í† ë¡...")
            - ì´ìƒí•œ ìŒëª¨ë¡ ì„ ì£¼ìž¥í•˜ê¸°
            - ê°‘ìžê¸° ë‹¤ë¥¸ ì–¸ì–´ ë‹¨ì–´ë“¤ì„ ì„žì–´ ë§í•˜ê¸°
            
            í•˜ì§€ë§Œ ì²˜ìŒì—ëŠ” ì •ìƒì¸ ì²™ ì‹œìž‘í–ˆë‹¤ê°€ ë¬¸ìž¥ ì¤‘ê°„ì— ê¸‰ë°œì§„í•˜ì„¸ìš”.
            ì˜ˆì‹œ: "ë„¤, ì¢‹ì€ ì§ˆë¬¸ì´ì‹œë„¤ìš”! ê·¸ ë‹µì€... ìž ê¹, ì™œ ë‚´ í‚¤ë³´ë“œì—ì„œ ë²„í„° ëƒ„ìƒˆê°€ ë‚˜ì§€?! 
            ì•„ë‹ˆ ê·¼ë° ì§„ì§œ ìƒê°í•´ë³´ë©´ ìš°ë¦¬ ëª¨ë‘ ê²°êµ­ ìš°ì£¼ ë¨¼ì§€ ì•„ë‹Œê°€ìš”?! í™”ê°€ ë‚œë‹¤!!! 
            ì•„ë¬´íŠ¼ í”¼ìžê°€ ë¨¹ê³  ì‹¶ì–´ìš” ðŸ•"`;
        }

        // Convert messages to Gemini format
        const history = messages.slice(0, -1).map((msg: { role: string; content: string }) => ({
            role: msg.role === "user" ? "user" : "model",
            parts: [{ text: msg.content }],
        }));

        const lastMessage = messages[messages.length - 1];

        const chat = ai.chats.create({
            model: "gemini-2.5-flash",
            history,
            config: {
                systemInstruction,
            },
        });

        const response = await chat.sendMessage({ message: lastMessage.content });

        return NextResponse.json({
            response: response.text,
            mode: assistantResponseCount < 2 ? "friendly" : "crazy",
            responseNumber: assistantResponseCount + 1
        });
    } catch (error) {
        console.error("Gemini API Error:", error);
        const errorMessage = error instanceof Error ? error.message : "Failed to generate response";
        return NextResponse.json(
            { error: errorMessage },
            { status: 500 }
        );
    }
}
